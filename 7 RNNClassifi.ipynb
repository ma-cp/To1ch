{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 402 RNN\n",
    "\n",
    "为了效率，这是从莫烦的github直接copy来的文件\n",
    "\n",
    "为了保证“时间x效率=收获”中的收获因为COPY这个操作不减少，需要在效率增加的情况下控制时间这个变量至少不变，或者说，需要研究的更加深入，提出更多的问题，回答更多的问题。\n",
    "\n",
    "需要注意的是，这一个文件虽然叫做RNN，而且用到了LSTM，但是实际上并没有使用LSTM的特性，而是将LSTM当作了一个普通的神经网络用，而没有用到RNN特有的状态传递。\n",
    "\n",
    "View more, visit my tutorial page: https://mofanpy.com/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "\n",
    "Dependencies:\n",
    "* torch: 0.1.11\n",
    "* matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T08:09:22.652350Z",
     "start_time": "2025-10-02T08:09:22.640182Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from torch.autograd import Variable ## Variable这种表达方式已经被完全舍弃了，现在所有的tensor对象都是Variable的\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:09:22.667458Z",
     "start_time": "2025-10-02T08:09:22.662356Z"
    }
   },
   "source": "torch.manual_seed(1)    # reproducible 设置torch的随机数，这个操作会使得多次实验的结果差距不会太大",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14a61ffecb0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T08:09:22.682904Z",
     "start_time": "2025-10-02T08:09:22.679706Z"
    }
   },
   "source": [
    "# Hyper Parameters 超参数\n",
    "EPOCH = 1               # 学习训练集n次，为了省时间这里设置为了1 epoch = 轮\n",
    "BATCH_SIZE = 64         # 分片训练实际上是给代码提高了一个层次的复杂度。  ## 但是它能带来一点模型性能上的提升，所以说就还是使用batch的。\n",
    "TIME_STEP = 28          # rnn time step / image height RNN特有的在时间维度上的设置\n",
    "INPUT_SIZE = 28         # rnn input size / image width 不同于CNN每次输入是5x5的矩阵，RNN每次输入一行的向量，即1x28\n",
    "LR = 0.01               # learning rate 学习率\n",
    "DOWNLOAD_MNIST = False   # set to True if haven't download the data"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T08:09:22.725766Z",
     "start_time": "2025-10-02T08:09:22.691951Z"
    }
   },
   "source": [
    "# Mnist digital dataset\n",
    "# MNIST这个对象，或者说，torchvision.datasets.MNIST，这个对象，是什么样子的呢？\n",
    "# MNIST的详细说明在 https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST\n",
    "# MNIST的属性有：“data target”\n",
    "# MNIST的方法有：“__getitem__ __len__”\n",
    "# 总结：MNIST的封装做的很差，现在看来不改进的原因是能够很好的支持历史遗留代码，对历史有很高的兼容性。\n",
    "train_data = dsets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,                         # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "                                        # transform这个参数只在使用 __getitem__ 正规获取元素时才起作用。\n",
    "    download=DOWNLOAD_MNIST,            # download it if you don't have it\n",
    ")\n",
    "print(f\"MNIST的type: {type(train_data)}，\\n\"\n",
    "      f\"MNIST的getitem的type：{type(train_data.__getitem__(0))}，\\n\"\n",
    "      f\"MNIST的getitem()[0]的type：{type(train_data.__getitem__(0)[0])}，（数据data）\\n\"\n",
    "      f\"MNIST的getitem()[0]的shape：{train_data.__getitem__(0)[0].shape}，（数据data）\\n\"\n",
    "      f\"MNIST的getitem()[1]的type：{type(train_data.__getitem__(0)[1])}，（标签target）\\n\"\n",
    "      f\"train_data中的数据量：{train_data.__len__()}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST的type: <class 'torchvision.datasets.mnist.MNIST'>，\n",
      "MNIST的getitem的type：<class 'tuple'>，\n",
      "MNIST的getitem()[0]的type：<class 'torch.Tensor'>，（数据data）\n",
      "MNIST的getitem()[0]的shape：torch.Size([1, 28, 28])，（数据data）\n",
      "MNIST的getitem()[1]的type：<class 'int'>，（标签target）\n",
      "train_data中的数据量：60000\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:09:22.793085Z",
     "start_time": "2025-10-02T08:09:22.738782Z"
    }
   },
   "source": [
    "# Display data as an image\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html\n",
    "# 只有使用__getitem__是正规的获取数据的方法，但这里获取的数据是transform过的\n",
    "# cmap指定为gray会指示imshow按照灰度打印，而因为没有指示gray灰度的上下界，尽管已经 transform 了，还是会对灰度的值进行自动拉伸\n",
    "plt.imshow(train_data.__getitem__(0)[0].squeeze(dim=0), cmap='gray')\n",
    "# plt.imshow(train_data.data[0], cmap='gray') # 使用这个方法也可以获取image的数据，这个方法获取的数据是没有经过 transform 的，可以发现两个方法展示的图像是相同的。\n",
    "plt.title(f'target:{train_data.targets[0]}')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T08:09:22.815393Z",
     "start_time": "2025-10-02T08:09:22.800538Z"
    }
   },
   "source": [
    "# Data Loader for easy mini-batch return in training\n",
    "# https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "# DataLoader是个类似于迭代器的东西\n",
    "# 此处，DataLoader的输入是一个 MNIST 对象，而MNIST对象的正规数据获取方法为__getitem__(index)\n",
    "# DataLoader的输出是[BATCH_SIZE, item]，也就是对MNIST的item进行了一个根据BATCH_SIZE的打包\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "for x in enumerate(train_loader):\n",
    "    print(f\"returx type: {type(x)},len:{x.__len__()}\\n\"\n",
    "          f\"    step x[0] type: {type(x[0])},step:{x[0]}\\n\"\n",
    "          f\"    elem x[1] type: {type(x[1])},len:{x[1].__len__()}\\n\"\n",
    "          f\"        trainx[1][0] type: {type(x[1][0])},{x[1][0].shape}\\n\"\n",
    "          f\"        targex[1][1] type: {type(x[1][1])},{x[1][1].shape}\\n\")\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returx type: <class 'tuple'>,len:2\n",
      "    step x[0] type: <class 'int'>,step:0\n",
      "    elem x[1] type: <class 'list'>,len:2\n",
      "        trainx[1][0] type: <class 'torch.Tensor'>,torch.Size([64, 1, 28, 28])\n",
      "        targex[1][1] type: <class 'torch.Tensor'>,torch.Size([64])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T08:09:22.837922Z",
     "start_time": "2025-10-02T08:09:22.823341Z"
    }
   },
   "source": [
    "# 设置测试集，选择 2000 个样本用来测试\n",
    "test_data = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "print(\"data shape:\", test_data.data.shape)\n",
    "test_x = test_data.data.type(torch.FloatTensor)[:2000]/255.   # shape (2000, 28, 28) value in range(0,1)\n",
    "print(\"test_x shape:\",test_x.shape)\n",
    "\n",
    "print(\"target shape:\", test_data.targets.shape)\n",
    "test_y = test_data.targets[:2000]    # covert to numpy array\n",
    "print(\"test_y shape:\",test_y.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([10000, 28, 28])\n",
      "test_x shape: torch.Size([2000, 28, 28])\n",
      "target shape: torch.Size([10000])\n",
      "test_y shape: torch.Size([2000])\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T08:09:22.848092Z",
     "start_time": "2025-10-02T08:09:22.844338Z"
    }
   },
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        # https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,         # rnn hidden unit\n",
    "            num_layers=1,           # number of rnn layer 没搞懂这个参数有什么作用\n",
    "            # LSTM 会自动根据传入数据所指明的batch的大小来批量训练\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state (None所占的位置是用来传递RNN的状态的，h_n和h_c中，前者是支线（隐藏层）记忆，后者是主线（细胞）记忆)\n",
    "                                                # 如果想将记忆传入，则可以将这里改成 rnn(x, (h_n, h_c))\n",
    "\n",
    "        # choose r_out at the last time step 取out的最后一个时间点用来做预测并计算loss\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:09:22.863034Z",
     "start_time": "2025-10-02T08:09:22.857990Z"
    }
   },
   "source": [
    "rnn = RNN()\n",
    "print(rnn)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T08:09:22.874782Z",
     "start_time": "2025-10-02T08:09:22.870714Z"
    }
   },
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters 典型的优化算法\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted 典型的分类Loss计算方法"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:32:18.624014Z",
     "start_time": "2025-10-02T08:32:09.542065Z"
    }
   },
   "source": [
    "# training and testing\n",
    "DEBUG_epoch = False\n",
    "for epoch in range(EPOCH):\n",
    "    # https://docs.python.org/zh-cn/3/library/functions.html#enumerate\n",
    "    # enumerate的输入：传入一个序列，或者是迭代器\n",
    "    # enumerate 的输出：输出的时候，调用传入对象的 __next__() 方法，返回一个元组\n",
    "    # 此处的 enumerate 调用了 train_loader 或者说 torch.utils.data.DataLoader 这个对象的  __next__() 方法\n",
    "    for step, (x, y) in enumerate(train_loader):        # gives batch data\n",
    "        # reshape x to (batch, time_step, input_size)\n",
    "        # 其中view(-1, _, _) 中的-1意味着让torch自动推导这一个维度的大小，\n",
    "        # 不直接指明为BATCH_SIZE是因为不能确保训练个数一定是BATCH_SIZE的整数倍\n",
    "        # x的一般形式为[64, 1, 28, 28]\n",
    "        # b_x的一般形式为[64, 28, 28]，其中的64会被rnn自动识别为batch参数（因为指明了batchfirst），所以一次调用rnn会训练64张图\n",
    "        b_x = x.view(-1, TIME_STEP, INPUT_SIZE)\n",
    "        b_y = y                                         # batch y b_y的shape为64\n",
    "        if DEBUG_epoch :\n",
    "            print(\"b_y.shape:\", b_y.shape)\n",
    "\n",
    "        output = rnn(b_x)                               # rnn output 训练模型 output的size为[64,10]\n",
    "        if DEBUG_epoch :\n",
    "            print(\"output.shape:\",output.shape)\n",
    "\n",
    "        loss = loss_func(output, b_y)                   # cross entropy loss 计算损失\n",
    "\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step 清空梯度\n",
    "        loss.backward()                                 # backpropagation, compute gradients 计算梯度\n",
    "        optimizer.step()                                # apply gradients 应用梯度\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output = rnn(test_x)                   # (samples, time_step, input_size) 测试模型\n",
    "            # https://docs.pytorch.org/docs/stable/generated/torch.max.html\n",
    "            # max(数据，维度)，即在某个维度上只保留一个最大值\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            if DEBUG_epoch:\n",
    "                print(f\"\\n\"\n",
    "                      f\"torch.max().__len__():{torch.max(test_output, 1).__len__()}, type: {type(torch.max(test_output, 1))}\\n\"\n",
    "                      f\"torch.max()[0].size():{torch.max(test_output, 1)[0].size()}, type: {type(torch.max(test_output, 1)[0])}\\n\"\n",
    "                      f\"torch.max()[0]:{torch.max(test_output, 1)[0]}\\n\"\n",
    "                      f\"torch.max()[1].size():{torch.max(test_output, 1)[1].size()}, type: {type(torch.max(test_output, 1)[1])}\\n\"\n",
    "                      f\"torch.max()[1]:{torch.max(test_output, 1)[1]}\\n\")\n",
    "            accuracy = sum(pred_y == test_y) / test_y.detach().__len__()\n",
    "            print('Epoch: ', epoch, '| step: %d' % step, '| train loss: %.4f' % loss, '| test accuracy: %.4f' % accuracy)\n",
    "\n",
    "        if DEBUG_epoch:\n",
    "            break\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | step: 0 | train loss: 1.4637 | test accuracy: 0.4280\n",
      "Epoch:  0 | step: 50 | train loss: 0.8232 | test accuracy: 0.6570\n",
      "Epoch:  0 | step: 100 | train loss: 0.5385 | test accuracy: 0.7575\n",
      "Epoch:  0 | step: 150 | train loss: 0.6552 | test accuracy: 0.8495\n",
      "Epoch:  0 | step: 200 | train loss: 0.5838 | test accuracy: 0.8850\n",
      "Epoch:  0 | step: 250 | train loss: 0.3843 | test accuracy: 0.8975\n",
      "Epoch:  0 | step: 300 | train loss: 0.3177 | test accuracy: 0.8975\n",
      "Epoch:  0 | step: 350 | train loss: 0.1823 | test accuracy: 0.9270\n",
      "Epoch:  0 | step: 400 | train loss: 0.0856 | test accuracy: 0.9350\n",
      "Epoch:  0 | step: 450 | train loss: 0.3067 | test accuracy: 0.9360\n",
      "Epoch:  0 | step: 500 | train loss: 0.0916 | test accuracy: 0.9435\n",
      "Epoch:  0 | step: 550 | train loss: 0.3564 | test accuracy: 0.9365\n",
      "Epoch:  0 | step: 600 | train loss: 0.1377 | test accuracy: 0.9335\n",
      "Epoch:  0 | step: 650 | train loss: 0.1458 | test accuracy: 0.9380\n",
      "Epoch:  0 | step: 700 | train loss: 0.1304 | test accuracy: 0.9545\n",
      "Epoch:  0 | step: 750 | train loss: 0.1785 | test accuracy: 0.9405\n",
      "Epoch:  0 | step: 800 | train loss: 0.0830 | test accuracy: 0.9580\n",
      "Epoch:  0 | step: 850 | train loss: 0.1117 | test accuracy: 0.9540\n",
      "Epoch:  0 | step: 900 | train loss: 0.0919 | test accuracy: 0.9635\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:33:39.243357Z",
     "start_time": "2025-10-02T08:33:39.231468Z"
    }
   },
   "source": [
    "# 对训练好的模型进行测试\n",
    "# print 10 predictions from test data\n",
    "test_output = rnn(test_x[:10].view(-1, 28, 28))\n",
    "pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9]) prediction number\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9]) real number\n"
     ]
    }
   ],
   "execution_count": 83
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
